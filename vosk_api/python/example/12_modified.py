#!/usr/bin/env python3

import wave
import sys
import requests
import json
import re
from vosk import Model, KaldiRecognizer, SetLogLevel
from collections import deque

# å…³é—­vosk debugæ—¥å¿—
SetLogLevel(0)

# å¯¹è¯å†å²é˜Ÿåˆ—ï¼Œä¿å­˜æœ€è¿‘ä¸¤è½®å¯¹è¯
chat_history = deque(maxlen=4)  # æ¯è½®åŒ…å«ç”¨æˆ·å’ŒåŠ©æ‰‹å„ä¸€å¥ï¼Œ4è¡¨ç¤º2è½®

# åŠ è½½éŸ³é¢‘æ–‡ä»¶
wf = wave.open(sys.argv[1], "rb")
if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
    print("éŸ³é¢‘æ–‡ä»¶å¿…é¡»ä¸º WAV æ ¼å¼å•å£°é“ PCMã€‚")
    sys.exit(1)

# åŠ è½½VOSKè¯­éŸ³è¯†åˆ«æ¨¡å‹
model = Model("/home/xuwei/vosk-build2/vosk-api/python/example/vosk-model-small-en-us-0.15")

# åˆå§‹åŒ–è¯†åˆ«å™¨
rec = KaldiRecognizer(model, wf.getframerate())
rec.SetWords(True)
rec.SetPartialWords(True)

# å­˜å‚¨æœ€ç»ˆè¯†åˆ«æ–‡æœ¬
final_text_list = []
count = 0

print("\nğŸ™ï¸ æ­£åœ¨è¯†åˆ«éŸ³é¢‘å†…å®¹...\n")
while True:
    data = wf.readframes(4000)
    count += 1
    if len(data) == 0:
        break
    if rec.AcceptWaveform(data):
        result = json.loads(rec.Result())
        text = result.get("text", "").strip()
        if text:  # è¿‡æ»¤æ‰ç©ºç™½ç»“æœ
            final_text_list.append(text)
            print(f"[è¯†åˆ«ç‰‡æ®µ {count}]ï¼š{text}")

# è·å–æœ€åè¯†åˆ«ç»“æœ
final_result = json.loads(rec.FinalResult())
final_text = final_result.get("text", "").strip()
if final_text:
    final_text_list.append(final_text)
    print(f"[æœ€ç»ˆè¯†åˆ«]ï¼š{final_text}")

# æ‹¼æ¥æ‰€æœ‰è¯†åˆ«æ–‡æœ¬
full_text = ' '.join(final_text_list)
print("\nğŸ“ è¯†åˆ«å®Œæˆï¼Œæ–‡æœ¬å¦‚ä¸‹ï¼š\n")
print(full_text)


# è°ƒç”¨ LLM çš„å‡½æ•°ï¼ˆå¸¦å†å²ä¸Šä¸‹æ–‡å’Œç³»ç»Ÿæç¤ºè¯ï¼‰
def llmchat_with_context(question):
    host = "http://localhost"
    port = "11434"
    model = "deepseek-r1:latest"

    url = f"{host}:{port}/api/chat"
    headers = {"Content-Type": "application/json"}

    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤å¸®å¿™æ‰§è¡Œä»»åŠ¡ï¼Œ"
        "ä¾‹å¦‚è®¾ç½®é—¹é’Ÿã€æé†’äº‹é¡¹ã€æ’­æ”¾éŸ³ä¹ã€æŸ¥è¯¢å¤©æ°”ã€å›ç­”é—®é¢˜ç­‰ï¼ŒåŒæ—¶ä½ ä¹Ÿæ˜¯ä¸€ä¸ªå‹å¥½å–„è°ˆçš„åŠ©æ‰‹ï¼Œ"
        "å¦‚æœç”¨æˆ·è·Ÿä½ é—²èŠï¼Œä½ ä¹Ÿå¯ä»¥è‡ªç„¶åœ°å›åº”ã€‚"
        "å¯¹äºæ˜ç¡®çš„ä»»åŠ¡ï¼Œè¯·ä»¥ã€å·²å¸®æ‚¨è®¾ç½®ã€‘ã€æé†’æ‚¨ã€‘ç­‰æ‰§è¡Œæ€§è¯­æ°”å›å¤ï¼Œ"
        "å¯¹äºèŠå¤©å†…å®¹ï¼Œè¯·ä»¥è½»æ¾è‡ªç„¶çš„è¯­æ°”å›åº”ï¼Œå¢åŠ äº²å’ŒåŠ›ã€‚"
        "å¦‚æœä¸æ¸…æ¥šç”¨æˆ·æ„å›¾ï¼Œè¯·å‹å¥½åœ°è¯·æ±‚å¯¹æ–¹æ¾„æ¸…é—®é¢˜ã€‚"
        
    )

    # æ„å»ºæ¶ˆæ¯ä½“ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºã€å†å²å¯¹è¯å’Œå½“å‰é—®é¢˜
    messages = [{"role": "system", "content": system_prompt}]

    # åŠ å…¥å†å²ä¸Šä¸‹æ–‡
    for msg in chat_history:
        messages.append(msg)

    # å½“å‰ç”¨æˆ·æé—®
    messages.append({"role": "user", "content": question})

    data = {
        "model": model,
        "options": {
            "temperature": 0.0
        },
        "stream": False,
        "messages": messages
    }

    try:
        response = requests.post(url, json=data, headers=headers, timeout=60)
        if response.status_code == 200:
            answer = response.json().get("message", {}).get("content", "")
            # æ¸…æ´—æ— å…³æ ¼å¼
            answer = re.sub(r'<think>.*?</think>', '', answer, flags=re.DOTALL)
            answer = re.sub(r'```json', '', answer)
            answer = re.sub(r'```', '', answer)
            return answer.strip()
        else:
            print(f"âŒ é”™è¯¯ï¼š{response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"âŒ å¼‚å¸¸ï¼š{e}")
        return None


# æ ¹æ®è¯†åˆ«å†…å®¹è°ƒç”¨å¤§æ¨¡å‹
if full_text:
    print("\nğŸ¤– æ­£åœ¨å‘å¤§æ¨¡å‹æé—®...\n")
    # è°ƒç”¨LLM
    answer = llmchat_with_context(full_text)

    if answer:
        print("\nğŸ’¡ å¤§æ¨¡å‹å›å¤å¦‚ä¸‹ï¼š\n")
        print(answer)
        # å­˜å‚¨æœ¬è½®å¯¹è¯åˆ°å†å²è®°å½•ï¼ˆç”¨æˆ·é—®é¢˜+åŠ©æ‰‹å›ç­”ï¼‰
        chat_history.append({"role": "user", "content": full_text})
        chat_history.append({"role": "assistant", "content": answer})
    else:
        print("âš ï¸ æœªèƒ½è·å¾—å¤§æ¨¡å‹å›å¤ã€‚")
else:
    print("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬ï¼Œæ— æ³•æé—®å¤§æ¨¡å‹ã€‚")
