#!/usr/bin/env python3

import wave
import requests
import json
import re
import os
from vosk import Model, KaldiRecognizer, SetLogLevel

# === å‚æ•°åŒº ===
HISTORY_ROUND = 2                 # æœ€è¿‘å¤šå°‘è½®å¯¹è¯
AUDIO_FILE = "rec5.wav"           # é»˜è®¤éŸ³é¢‘æ–‡ä»¶è·¯å¾„

# å…³é—­ vosk debug æ—¥å¿—
SetLogLevel(0)

# === å…¨å±€å¯¹è¯å†…å­˜ï¼ˆä»£æ›¿æ–‡ä»¶ï¼‰ ===
conversation_memory = []  # å½¢å¦‚ [{"role": "user", "content": "xxx"}, {"role": "assistant", "content": "yyy"}, ...]

# === æ·»åŠ ä¸€è½®å¯¹è¯åˆ°å†…å­˜ ===
def add_to_memory(user_text, ai_text, memory, max_rounds=2):
    memory.append({"role": "user", "content": user_text})
    memory.append({"role": "assistant", "content": ai_text})
    # ä¿ç•™æœ€è¿‘ max_rounds è½®
    if len(memory) > max_rounds * 2:
        memory[:] = memory[-max_rounds * 2:]

# === è°ƒç”¨ LLM èŠå¤©ï¼Œå†…å­˜ä¸­ä¿ç•™å†å² ===
def llmchat(question):
    host = "http://localhost"
    port = "11434"
    model = "deepseek-r1:latest"

    url = f"{host}:{port}/api/chat"
    headers = {"Content-Type": "application/json"}

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤å¸®å¿™æ‰§è¡Œä»»åŠ¡ï¼Œ"
        "ä¾‹å¦‚è®¾ç½®é—¹é’Ÿã€æé†’äº‹é¡¹ã€æ’­æ”¾éŸ³ä¹ã€æŸ¥è¯¢å¤©æ°”ã€å›ç­”é—®é¢˜ç­‰ï¼ŒåŒæ—¶ä½ ä¹Ÿæ˜¯ä¸€ä¸ªå‹å¥½å–„è°ˆçš„åŠ©æ‰‹ï¼Œ"
        "å¦‚æœç”¨æˆ·è·Ÿä½ é—²èŠï¼Œä½ ä¹Ÿå¯ä»¥è‡ªç„¶åœ°å›åº”ã€‚"
        "å¯¹äºæ˜ç¡®çš„ä»»åŠ¡ï¼Œè¯·ä»¥ã€å·²å¸®æ‚¨è®¾ç½®ã€‘ã€æé†’æ‚¨ã€‘ç­‰æ‰§è¡Œæ€§è¯­æ°”å›å¤ï¼Œ"
        "å¯¹äºèŠå¤©å†…å®¹ï¼Œè¯·ä»¥è½»æ¾è‡ªç„¶çš„è¯­æ°”å›åº”ï¼Œå¢åŠ äº²å’ŒåŠ›ã€‚"
        "å¦‚æœä¸æ¸…æ¥šç”¨æˆ·æ„å›¾ï¼Œè¯·å‹å¥½åœ°è¯·æ±‚å¯¹æ–¹æ¾„æ¸…é—®é¢˜ã€‚"
        "æ³¨æ„ï¼šå¿…é¡»ç”¨è‹±æ–‡å›å¤ã€‚"
    )

    messages = [{"role": "system", "content": system_prompt}] + conversation_memory
    messages.append({"role": "user", "content": question})

    data = {
        "model": model,
        "options": {"temperature": 0.0},
        "stream": False,
        "messages": messages
    }

    try:
        response = requests.post(url, json=data, headers=headers, timeout=60)
        if response.status_code == 200:
            answer = response.json().get("message", {}).get("content", "")
            # å»æ‰æ— å…³å­—ç¬¦
            answer = re.sub(r'<think>.*?</think>', '', answer, flags=re.DOTALL)
            answer = re.sub(r'```json', '', answer)
            answer = re.sub(r'```', '', answer)
            return answer.strip()
        else:
            print(f"âŒ é”™è¯¯ï¼š{response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"âŒ å¼‚å¸¸ï¼š{e}")
        return None

# === éŸ³é¢‘è¯†åˆ«å¹¶è°ƒç”¨å¤§æ¨¡å‹ä¸»å‡½æ•° ===
def process_audio_and_chat():
    # === åŠ è½½éŸ³é¢‘æ–‡ä»¶ ===
    if not os.path.exists(AUDIO_FILE):
        print(f"âš ï¸ æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶ {AUDIO_FILE}")
        return "Audio file not found."

    wf = wave.open(AUDIO_FILE, "rb")
    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
        print("âš ï¸ éŸ³é¢‘æ–‡ä»¶å¿…é¡»ä¸º WAV æ ¼å¼å•å£°é“ PCMã€‚")
        return "Invalid audio file format."

    # === åŠ è½½ VOSK è¯­éŸ³è¯†åˆ«æ¨¡å‹ ===
    model = Model("/home/xuwei/vosk-build2/vosk_api/python/example/vosk-model-small-en-us-0.15")
    rec = KaldiRecognizer(model, wf.getframerate())
    rec.SetWords(True)
    rec.SetPartialWords(True)

    # === è¯†åˆ«éŸ³é¢‘ ===
    final_text_list = []
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            text = result.get("text", "").strip()
            if text:
                final_text_list.append(text)

    final_result = json.loads(rec.FinalResult())
    final_text = final_result.get("text", "").strip()
    if final_text:
        final_text_list.append(final_text)

    full_text = ' '.join(final_text_list).strip()

    if not full_text:
        print("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬ï¼Œæ— æ³•æé—®å¤§æ¨¡å‹ã€‚")
        return "No valid speech recognized."

    print(f"\nğŸ“ è¯†åˆ«å®Œæˆæ–‡æœ¬ï¼š{full_text}\n")

    # === è°ƒç”¨å¤§æ¨¡å‹ ===
    print("\nğŸ¤– æ­£åœ¨å‘å¤§æ¨¡å‹æé—®...\n")
    answer = llmchat(full_text)

    if answer:
        print("\nğŸ’¡ å¤§æ¨¡å‹å›å¤å¦‚ä¸‹ï¼š\n")
        print(answer)
        add_to_memory(full_text, answer, conversation_memory, max_rounds=HISTORY_ROUND)
        return answer
    else:
        print("âš ï¸ æœªèƒ½è·å¾—å¤§æ¨¡å‹å›å¤ã€‚")
        return "Failed to get response from LLM."

# === æµ‹è¯•è°ƒç”¨ ===
if __name__ == "__main__":
    result = process_audio_and_chat()
    print("\nâœ… æœ€ç»ˆè¿”å›ç»“æœï¼š", result)
